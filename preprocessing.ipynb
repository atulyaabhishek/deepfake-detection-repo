{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2deda22-b5a1-4483-978a-dab887cc302e",
   "metadata": {},
   "source": [
    "# Building a Deepfake Detector using Deep Learning Models\n",
    "This notebook demonstrates the development of a deepfake detection system using multiple pre-trained **CNN (Convolutional Neural Network)** models, such as **ResNet50**, **EfficientNetV2B0** and **Xception**, combined with **LSTM (Long Short-Term Memory)** networks for temporal analysis. The datasets used are **FaceForensics++**, **DFDC** and **Celeb-DF (v2)**. To ensure unbiased testing, the **Celeb-DF (v2)** dataset consists of completely unseen videos that are exclusively reserved for testing and are not included in the training or validation processes. `OpenCV` is utilized for video frame extraction and preprocessing while `dlib` is used for face detection and cropping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6ea372-1154-4900-acd4-27188a74a144",
   "metadata": {},
   "source": [
    "## GPU Configuration and Verification with TensorFlow\n",
    "To ensure TensorFlow is configured to effectively utilize the GPU for deep learning tasks, optimize memory usage and verify GPU support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52f34d21-2251-4a7b-a752-490c33099c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow CUDA Support: True\n",
      "Num GPUs Available: 1\n",
      "Enabled memory growth for GPU 0: NVIDIA GeForce 940MX\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if TensorFlow is built with CUDA support and list GPUs\n",
    "print(\"TensorFlow CUDA Support:\", tf.test.is_built_with_cuda())\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available:\", len(physical_devices))\n",
    "\n",
    "if physical_devices:\n",
    "    try:\n",
    "        for i, gpu in enumerate(physical_devices):\n",
    "            # Enable memory growth for each GPU\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(f\"Enabled memory growth for GPU {i}: {tf.config.experimental.get_device_details(gpu)['device_name']}\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"Error enabling GPU memory growth:\", e)\n",
    "else:\n",
    "    print(\"No GPU detected. Ensure proper GPU setup.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736d1612-f084-4f65-9623-408bb9ea0fae",
   "metadata": {},
   "source": [
    "## Importing Libraries and Setup\n",
    "Importing all necessary libraries at the top to ensure better organization, easy debugging and smooth execution of the entire pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d11407ff-6aa0-4e6a-bd98-d4f017401ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import shutil\n",
    "import cv2\n",
    "import dlib\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec146551-8c23-4805-8a1e-919809472d79",
   "metadata": {},
   "source": [
    "## 1. Dataset Preparation\n",
    "Preparing the dataset for video frame extraction, face detection and cropping followed by organizing the data into structured train and validation directories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679ca3c3-d14f-4812-89fc-aadc29436284",
   "metadata": {},
   "source": [
    "### 1.1 Defining Paths and Creating Directories for Training and Validation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6675bad5-3246-4409-be65-c53d78dd1d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories for processing and output:\n",
      "Real Videos: C:\\Users\\atul\\Datasets\\FaceForensic++\\real\n",
      "Fake Videos: C:\\Users\\atul\\Datasets\\FaceForensic++\\fake\n",
      "Real Faces: C:\\Users\\atul\\Cropped_Faces\\real\n",
      "Fake Faces: C:\\Users\\atul\\Cropped_Faces\\fake\n",
      "Train Directory: C:\\Users\\atul\\Cropped_Faces\\train\n",
      "Validation Directory: C:\\Users\\atul\\Cropped_Faces\\val\n"
     ]
    }
   ],
   "source": [
    "# Defining base directory where the dataset resides\n",
    "base_dir = os.getcwd() # Current working directory where my Jupyter Notebook is located\n",
    "\n",
    "# Defining paths for dataset directories\n",
    "real_videos_dir = os.path.join(base_dir, \"Datasets\", \"FaceForensic++\", \"real\")\n",
    "fake_videos_dir = os.path.join(base_dir, \"Datasets\", \"FaceForensic++\", \"fake\")\n",
    "\n",
    "# Defining paths for cropped faces directories\n",
    "real_faces_dir = os.path.join(base_dir, \"Cropped_Faces\", \"real\")\n",
    "fake_faces_dir = os.path.join(base_dir, \"Cropped_Faces\", \"fake\")\n",
    "\n",
    "# Defining paths for training and validation directories\n",
    "train_dir = os.path.join(base_dir, \"Cropped_Faces\", \"train\")\n",
    "val_dir = os.path.join(base_dir, \"Cropped_Faces\", \"val\")\n",
    "\n",
    "# Creating necessary directories if they donâ€™t already exist\n",
    "os.makedirs(real_faces_dir, exist_ok=True)\n",
    "os.makedirs(fake_faces_dir, exist_ok=True)\n",
    "os.makedirs(os.path.join(train_dir, \"real\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(train_dir, \"fake\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(val_dir, \"real\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(val_dir, \"fake\"), exist_ok=True)\n",
    "\n",
    "print(f\"Directories for processing and output:\")\n",
    "print(f\"Real Videos: {real_videos_dir}\")\n",
    "print(f\"Fake Videos: {fake_videos_dir}\")\n",
    "print(f\"Real Faces: {real_faces_dir}\")\n",
    "print(f\"Fake Faces: {fake_faces_dir}\")\n",
    "print(f\"Train Directory: {train_dir}\")\n",
    "print(f\"Validation Directory: {val_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beae802f-3517-42b3-a5cd-c3e053d9e3e2",
   "metadata": {},
   "source": [
    "### 1.2 Face Detection and Cropping for Training and Validation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f20b40b-2460-4685-a101-5250c975d36a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing Real videos from FaceForensic++ dataset ---\n",
      "--- Face cropping complete ---\n",
      "\n",
      "--- Processing Fake videos from FaceForensic++ dataset ---\n",
      "--- Face cropping complete ---\n"
     ]
    }
   ],
   "source": [
    "# Initializing the face detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "def crop_faces(input_dir, output_dir, dataset_name, face_size=(224, 224), is_real=True):\n",
    "    \"\"\"\n",
    "    Detects and crops faces from videos in the input directory.\n",
    "    Cropped faces are saved in specific folders with unique names in the output directory.\n",
    "\n",
    "    Args:\n",
    "    - input_dir (str): Path to the directory containing videos.\n",
    "    - output_dir (str): Path to the directory to save cropped face images.\n",
    "    - dataset_name (str): Prefix for naming folders and files (e.g., dataset name).\n",
    "    - face_size (tuple): Dimensions to resize each face (width, height).\n",
    "    - is_real (bool): Indicates whether the videos are from the \"real\" or \"fake\" category.\n",
    "    \"\"\"\n",
    "    # Check if input and output directories exist\n",
    "    if not os.path.exists(input_dir):\n",
    "        print(f\"Input directory {input_dir} does not exist. Skipping.\")\n",
    "        return\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Supported video formats\n",
    "    supported_formats = (\".mp4\", \".avi\", \".mkv\", \".mov\")\n",
    "\n",
    "    # Initialize folder counter\n",
    "    folder_counter = 0\n",
    "\n",
    "    # Looping through each file in the input directory\n",
    "    for file in os.listdir(input_dir):\n",
    "        if file.lower().endswith(supported_formats):  # Process only supported video files\n",
    "            video_name = os.path.splitext(file)[0]  # Extract the video name (without extension)\n",
    "\n",
    "            # Generate a unique folder name based on the dataset name and category\n",
    "            category = \"real\" if is_real else \"fake\"\n",
    "            folder_name = f\"{dataset_name}_{category}{folder_counter}\"\n",
    "            folder_counter += 1\n",
    "\n",
    "            # Create the unique folder\n",
    "            folder_path = os.path.join(output_dir, folder_name)\n",
    "\n",
    "            # Skip already processed videos\n",
    "            if os.path.exists(folder_path) and len(os.listdir(folder_path)) > 0:\n",
    "                print(f\"Skipping already processed video: {file}\")\n",
    "                continue\n",
    "\n",
    "            os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "            video_path = os.path.join(input_dir, file)\n",
    "            cap = cv2.VideoCapture(video_path)  # Open the video file\n",
    "\n",
    "            if not cap.isOpened():\n",
    "                print(f\"Failed to open video {file}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            frame_count = 0\n",
    "            cropped_count = 0  # Counter for cropped faces\n",
    "\n",
    "            # Looping through frames in the video\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()  # Read a frame\n",
    "                if not ret:  # Exit when no more frames\n",
    "                    break\n",
    "\n",
    "                frame_count += 1\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Convert frame to grayscale\n",
    "                faces = detector(gray)  # Detect faces in the frame\n",
    "\n",
    "                # Save each detected face\n",
    "                for i, face in enumerate(faces):\n",
    "                    x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "\n",
    "                    # Validate face coordinates to ensure they are within the frame bounds\n",
    "                    x = max(0, x)\n",
    "                    y = max(0, y)\n",
    "                    w = min(frame.shape[1] - x, w)\n",
    "                    h = min(frame.shape[0] - y, h)\n",
    "\n",
    "                    if w <= 0 or h <= 0:  # Check if the cropped region is valid\n",
    "                        print(f\"Invalid face region in frame {frame_count}, video {file}. Skipping.\")\n",
    "                        continue\n",
    "\n",
    "                    # Crop the face from the frame\n",
    "                    cropped_face = frame[y:y+h, x:x+w]\n",
    "\n",
    "                    # Resize the cropped face to the specified size\n",
    "                    cropped_face = cv2.resize(cropped_face, face_size)\n",
    "\n",
    "                    # Generate a unique filename for the cropped face\n",
    "                    file_name = f\"{folder_name}_frame{frame_count}_face{i}.jpg\"\n",
    "                    save_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "                    # Save the cropped face\n",
    "                    cv2.imwrite(save_path, cropped_face)\n",
    "                    cropped_count += 1  # Increment the cropped face counter\n",
    "\n",
    "            cap.release()  # Release the video capture object\n",
    "            print(f\"Processed {file}: {cropped_count} face(s) cropped into {folder_name}.\")\n",
    "    print(\"--- Face cropping complete ---\")\n",
    "\n",
    "# Process real videos\n",
    "print(\"--- Processing Real videos from FaceForensic++ dataset ---\")\n",
    "crop_faces(real_videos_dir, real_faces_dir, \"FF\", is_real=True)\n",
    "\n",
    "# Process fake videos\n",
    "print(\"\\n--- Processing Fake videos from FaceForensic++ dataset ---\")\n",
    "crop_faces(fake_videos_dir, fake_faces_dir, \"FF\", is_real=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f7ac48-83f5-4d19-96a5-28330eaa9d21",
   "metadata": {},
   "source": [
    "### 1.3 Organizing the Dataset into Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe954a69-3dd3-48b4-b099-69c7bc048691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Dataset Preparation Already Completed. Skipping Step. ---\n",
      "\n",
      "Note: The 'dataset_preparation_done.flag' file is generated to prevent re-running this step.\n",
      "If you want to re-run the dataset preparation, please delete the 'dataset_preparation_done.flag' file and re-run the code.\n"
     ]
    }
   ],
   "source": [
    "# Prevent accidental re-run by checking for a flag file\n",
    "flag_file = \"dataset_preparation_done.flag\"\n",
    "\n",
    "if os.path.exists(flag_file):\n",
    "    print(\"--- Dataset Preparation Already Completed. Skipping Step. ---\\n\")\n",
    "    print(\"Note: The 'dataset_preparation_done.flag' file is generated to prevent re-running this step.\")\n",
    "    print(\"If you want to re-run the dataset preparation, please delete the 'dataset_preparation_done.flag' file and re-run the code.\")\n",
    "else:\n",
    "    # Defining base directory and paths for real and fake cropped faces\n",
    "    print(\"\\n--- Dataset Preparation Started ---\\n\")\n",
    "    base_dir = os.getcwd()\n",
    "    real_faces_dir = os.path.join(base_dir, \"Cropped_Faces\", \"real\")\n",
    "    fake_faces_dir = os.path.join(base_dir, \"Cropped_Faces\", \"fake\")\n",
    "\n",
    "    # Defining train and validation directories\n",
    "    train_dir = os.path.join(base_dir, \"Cropped_Faces\", \"train\")\n",
    "    val_dir = os.path.join(base_dir, \"Cropped_Faces\", \"val\")\n",
    "\n",
    "    print(\"Ensuring that train and validation directories exist...\")\n",
    "    # Ensuring train and validation directories exist\n",
    "    os.makedirs(os.path.join(train_dir, \"real\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(val_dir, \"real\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(train_dir, \"fake\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(val_dir, \"fake\"), exist_ok=True)\n",
    "    print(\"Directory structure for train and validation sets created.\\n\")\n",
    "\n",
    "    # Function to recursively collect all .jpg files from subdirectories\n",
    "    def collect_images_from_subfolders(root_dir):\n",
    "        image_files = []\n",
    "        for subdir, _, files in os.walk(root_dir):\n",
    "            for file in files:\n",
    "                if file.endswith(\".jpg\"):\n",
    "                    image_files.append(os.path.join(subdir, file))\n",
    "        return image_files\n",
    "\n",
    "    # Collect real and fake face images\n",
    "    print(\"Collecting images for real and fake faces...\")\n",
    "    real_faces = collect_images_from_subfolders(real_faces_dir)\n",
    "    fake_faces = collect_images_from_subfolders(fake_faces_dir)\n",
    "\n",
    "    print(f\"Found {len(real_faces)} real face images.\")\n",
    "    print(f\"Found {len(fake_faces)} fake face images.\\n\")\n",
    "\n",
    "    # Check for empty datasets\n",
    "    if not real_faces or not fake_faces:\n",
    "        print(\"Error: One or more directories are empty. Please ensure face cropping is successful.\")\n",
    "    else:\n",
    "        print(\"Splitting dataset into training and validation sets...\")\n",
    "        # Split data into train and validation sets\n",
    "        real_train, real_val = train_test_split(real_faces, test_size=0.2, random_state=42)\n",
    "        fake_train, fake_val = train_test_split(fake_faces, test_size=0.2, random_state=42)\n",
    "        print(\"Dataset split complete.\\n\")\n",
    "\n",
    "        # Function to move files while preserving subfolders\n",
    "        def move_files_with_subfolders(file_list, target_dir, base_dir):\n",
    "            for file_path in file_list:\n",
    "                # Compute the relative path from the base directory\n",
    "                relative_path = os.path.relpath(file_path, base_dir)\n",
    "                # Create the corresponding subfolder structure in the target directory\n",
    "                destination_path = os.path.join(target_dir, os.path.dirname(relative_path))\n",
    "                os.makedirs(destination_path, exist_ok=True)\n",
    "                # Move the file to the target directory\n",
    "                shutil.copy(file_path, os.path.join(destination_path, os.path.basename(file_path)))\n",
    "\n",
    "        # Move the split data to respective directories while preserving subfolders\n",
    "        print(\"Moving real face images to train and validation directories (preserving subfolders)...\")\n",
    "        move_files_with_subfolders(real_train, os.path.join(train_dir, \"real\"), real_faces_dir)\n",
    "        move_files_with_subfolders(real_val, os.path.join(val_dir, \"real\"), real_faces_dir)\n",
    "        print(\"Real face images successfully moved.\\n\")\n",
    "\n",
    "        print(\"Moving fake face images to train and validation directories (preserving subfolders)...\")\n",
    "        move_files_with_subfolders(fake_train, os.path.join(train_dir, \"fake\"), fake_faces_dir)\n",
    "        move_files_with_subfolders(fake_val, os.path.join(val_dir, \"fake\"), fake_faces_dir)\n",
    "        print(\"Fake face images successfully moved.\\n\")\n",
    "\n",
    "        print(\"Data split and moved to train and validation directories successfully.\")\n",
    "\n",
    "        # Create flag file to indicate completion\n",
    "        with open(flag_file, \"w\") as f:\n",
    "            f.write(\"Dataset preparation completed.\\n\")\n",
    "        print(\"\\n--- Dataset Preparation Complete ---\\n\")\n",
    "\n",
    "        # Explicit note for users about the flag file\n",
    "        print(\"Note: The 'dataset_preparation_done.flag' file is generated to prevent re-running this step.\")\n",
    "        print(\"If you want to re-run the dataset preparation, please delete the 'dataset_preparation_done.flag' file and re-run the code.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3a6bd6-0380-4746-8b43-86df4bc037f0",
   "metadata": {},
   "source": [
    "### 1.4 Defining Paths and Creating Directories for the Testing Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c113516-ac29-4c99-b4d0-98e5eb2d3b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories for Test:\n",
      "Real Videos Directory: C:\\Users\\atul\\Datasets\\CelebDFv2\\real\n",
      "Fake Videos Directory: C:\\Users\\atul\\Datasets\\CelebDFv2\\fake\n",
      "Real Faces Directory: C:\\Users\\atul\\Cropped_Faces\\test\\real\n",
      "Fake Faces Directory: C:\\Users\\atul\\Cropped_Faces\\test\\fake\n"
     ]
    }
   ],
   "source": [
    "# Defining base directory where the dataset resides\n",
    "base_dir = os.getcwd() # Current working directory where my Jupyter Notebook is located\n",
    "\n",
    "# Defining paths for dataset directories\n",
    "real_videos_dir = os.path.join(base_dir, \"Datasets\", \"CelebDFv2\", \"real\")\n",
    "fake_videos_dir = os.path.join(base_dir, \"Datasets\", \"CelebDFv2\", \"fake\")\n",
    "\n",
    "# Defining paths for cropped faces directories\n",
    "real_faces_dir = os.path.join(base_dir, \"Cropped_Faces\", \"test\", \"real\")\n",
    "fake_faces_dir = os.path.join(base_dir, \"Cropped_Faces\", \"test\", \"fake\")\n",
    "\n",
    "# Creating necessary directories if they donâ€™t already exist\n",
    "os.makedirs(real_faces_dir, exist_ok=True)\n",
    "os.makedirs(fake_faces_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Directories for Test:\")\n",
    "print(f\"Real Videos Directory: {real_videos_dir}\")\n",
    "print(f\"Fake Videos Directory: {fake_videos_dir}\")\n",
    "print(f\"Real Faces Directory: {real_faces_dir}\")\n",
    "print(f\"Fake Faces Directory: {fake_faces_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a481d3a-3d3b-43a6-8858-df984ee3adeb",
   "metadata": {},
   "source": [
    "### 1.5 Face Detection and Cropping for the Testing Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fcbcb55-8436-4cee-b1fc-1d1c312b1ade",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing Real videos from Celeb-DF (v2) dataset ---\n",
      "--- Face cropping complete ---\n",
      "\n",
      "--- Processing Fake videos from Celeb-DF (v2) dataset ---\n",
      "--- Face cropping complete ---\n"
     ]
    }
   ],
   "source": [
    "# Initializing the face detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "def crop_faces(input_dir, output_dir, dataset_name, face_size=(224, 224), is_real=True):\n",
    "    \"\"\"\n",
    "    Detects and crops faces from videos in the input directory.\n",
    "    Cropped faces are saved in specific folders with unique names in the output directory.\n",
    "\n",
    "    Args:\n",
    "    - input_dir (str): Path to the directory containing videos.\n",
    "    - output_dir (str): Path to the directory to save cropped face images.\n",
    "    - dataset_name (str): Prefix for naming folders and files (e.g., dataset name).\n",
    "    - face_size (tuple): Dimensions to resize each face (width, height).\n",
    "    - is_real (bool): Indicates whether the videos are from the \"real\" or \"fake\" category.\n",
    "    \"\"\"\n",
    "    # Check if input and output directories exist\n",
    "    if not os.path.exists(input_dir):\n",
    "        print(f\"Input directory {input_dir} does not exist. Skipping.\")\n",
    "        return\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Supported video formats\n",
    "    supported_formats = (\".mp4\", \".avi\", \".mkv\", \".mov\")\n",
    "\n",
    "    # Initialize folder counter\n",
    "    folder_counter = 0\n",
    "\n",
    "    # Looping through each file in the input directory\n",
    "    for file in os.listdir(input_dir):\n",
    "        if file.lower().endswith(supported_formats):  # Process only supported video files\n",
    "            video_name = os.path.splitext(file)[0]  # Extract the video name (without extension)\n",
    "\n",
    "            # Generate a unique folder name based on the dataset name and category\n",
    "            category = \"real\" if is_real else \"fake\"\n",
    "            folder_name = f\"{dataset_name}_{category}{folder_counter}\"\n",
    "            folder_counter += 1\n",
    "\n",
    "            # Create the unique folder\n",
    "            folder_path = os.path.join(output_dir, folder_name)\n",
    "\n",
    "            # Skip already processed videos\n",
    "            if os.path.exists(folder_path) and len(os.listdir(folder_path)) > 0:\n",
    "                print(f\"Skipping already processed video: {file}\")\n",
    "                continue\n",
    "\n",
    "            os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "            video_path = os.path.join(input_dir, file)\n",
    "            cap = cv2.VideoCapture(video_path)  # Open the video file\n",
    "\n",
    "            if not cap.isOpened():\n",
    "                print(f\"Failed to open video {file}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            frame_count = 0\n",
    "            cropped_count = 0  # Counter for cropped faces\n",
    "\n",
    "            # Looping through frames in the video\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()  # Read a frame\n",
    "                if not ret:  # Exit when no more frames\n",
    "                    break\n",
    "\n",
    "                frame_count += 1\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Convert frame to grayscale\n",
    "                faces = detector(gray)  # Detect faces in the frame\n",
    "\n",
    "                # Save each detected face\n",
    "                for i, face in enumerate(faces):\n",
    "                    x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "\n",
    "                    # Validate face coordinates to ensure they are within the frame bounds\n",
    "                    x = max(0, x)\n",
    "                    y = max(0, y)\n",
    "                    w = min(frame.shape[1] - x, w)\n",
    "                    h = min(frame.shape[0] - y, h)\n",
    "\n",
    "                    if w <= 0 or h <= 0:  # Check if the cropped region is valid\n",
    "                        print(f\"Invalid face region in frame {frame_count}, video {file}. Skipping.\")\n",
    "                        continue\n",
    "\n",
    "                    # Crop the face from the frame\n",
    "                    cropped_face = frame[y:y+h, x:x+w]\n",
    "\n",
    "                    # Resize the cropped face to the specified size\n",
    "                    cropped_face = cv2.resize(cropped_face, face_size)\n",
    "\n",
    "                    # Generate a unique filename for the cropped face\n",
    "                    file_name = f\"{folder_name}_frame{frame_count}_face{i}.jpg\"\n",
    "                    save_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "                    # Save the cropped face\n",
    "                    cv2.imwrite(save_path, cropped_face)\n",
    "                    cropped_count += 1  # Increment the cropped face counter\n",
    "\n",
    "            cap.release()  # Release the video capture object\n",
    "            print(f\"Processed {file}: {cropped_count} face(s) cropped into {folder_name}.\")\n",
    "    print(\"--- Face cropping complete ---\")\n",
    "\n",
    "# Process real videos\n",
    "print(\"--- Processing Real videos from Celeb-DF (v2) dataset ---\")\n",
    "crop_faces(real_videos_dir, real_faces_dir, \"cdfv2\", is_real=True)\n",
    "\n",
    "# Process fake videos\n",
    "print(\"\\n--- Processing Fake videos from Celeb-DF (v2) dataset ---\")\n",
    "crop_faces(fake_videos_dir, fake_faces_dir, \"cdfv2\", is_real=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c238e465-8647-43b7-aac5-1c79542eb75f",
   "metadata": {},
   "source": [
    "## 2. Dynamic Calculation of Training, Validation and Testing Dataset Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "517d03c8-fcf2-4fc0-bc58-ea759e6310c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Size: 262642 (Real: 139606, Fake: 123036)\n",
      "Validation Dataset Size: 65662 (Real: 34902, Fake: 30760)\n",
      "Testing Dataset Size: 176050 (Real: 89826, Fake: 86224)\n"
     ]
    }
   ],
   "source": [
    "def count_images_in_class(directory, class_name):\n",
    "    class_dir = os.path.join(directory, class_name)\n",
    "    image_extensions = ('.jpg', '.jpeg', '.png')  # Supported image formats\n",
    "    count = 0\n",
    "    for root, _, files in os.walk(class_dir):\n",
    "        count += sum(1 for file in files if file.lower().endswith(image_extensions))\n",
    "    return count\n",
    "\n",
    "def calculate_dataset_sizes(train_dir, val_dir):\n",
    "    # Count for train\n",
    "    train_real_count = count_images_in_class(train_dir, \"real\")\n",
    "    train_fake_count = count_images_in_class(train_dir, \"fake\")\n",
    "    train_dataset_size = train_real_count + train_fake_count\n",
    "\n",
    "    # Count for val\n",
    "    val_real_count = count_images_in_class(val_dir, \"real\")\n",
    "    val_fake_count = count_images_in_class(val_dir, \"fake\")\n",
    "    val_dataset_size = val_real_count + val_fake_count\n",
    "\n",
    "    return train_real_count, train_fake_count, train_dataset_size, val_real_count, val_fake_count, val_dataset_size\n",
    "\n",
    "def calculate_test_dataset_size(test_dir):\n",
    "    # Count for val\n",
    "    test_real_count = count_images_in_class(test_dir, \"real\")\n",
    "    test_fake_count = count_images_in_class(test_dir, \"fake\")\n",
    "    test_dataset_size = test_real_count + test_fake_count\n",
    "\n",
    "    return test_real_count, test_fake_count, test_dataset_size\n",
    "\n",
    "# Define paths to train, validation, and test directories\n",
    "base_dir = os.getcwd()\n",
    "train_dir = os.path.join(base_dir, \"Cropped_Faces\", \"train\")\n",
    "val_dir = os.path.join(base_dir, \"Cropped_Faces\", \"val\")\n",
    "test_dir = os.path.join(base_dir, \"Cropped_Faces\", \"test\")\n",
    "\n",
    "# Calculate sizes dynamically\n",
    "train_real_count, train_fake_count, train_dataset_size, val_real_count, val_fake_count, val_dataset_size = calculate_dataset_sizes(train_dir, val_dir)\n",
    "\n",
    "# Calculate size for test dataset\n",
    "test_real_count, test_fake_count, test_dataset_size = calculate_test_dataset_size(test_dir)\n",
    "\n",
    "# Print output in the desired format\n",
    "print(f\"Training Dataset Size: {train_dataset_size} (Real: {train_real_count}, Fake: {train_fake_count})\")\n",
    "print(f\"Validation Dataset Size: {val_dataset_size} (Real: {val_real_count}, Fake: {val_fake_count})\")\n",
    "print(f\"Testing Dataset Size: {test_dataset_size} (Real: {test_real_count}, Fake: {test_fake_count})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da04907c-2e15-4ad7-b0f5-59f7ae7b41d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
